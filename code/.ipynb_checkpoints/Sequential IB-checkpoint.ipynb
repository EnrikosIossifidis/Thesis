{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose\n",
    "from scipy.stats import binom\n",
    "from dit import Distribution\n",
    "from dit.algorithms.lattice import join\n",
    "from itertools import combinations\n",
    "import itertools, string, dit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import random\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(n_vars: int, n_states: int):\n",
    "    if n_states < 1 or n_states > 10:\n",
    "        raise ValueError(\"states should be greater than 0 and  less than or equal to 10\")\n",
    "    return [''.join(i) for i in itertools.product(string.digits[:n_states], repeat=n_vars)]\n",
    "\n",
    "def get_vars(n_vars: int):\n",
    "    vs = ['X{}'.format(i) for i in range(n_vars-1)]\n",
    "    vs.append('Y')\n",
    "    return vs\n",
    "\n",
    "def random_dist(l):\n",
    "    s = 1\n",
    "    d = []\n",
    "    c = 0\n",
    "    while s > 0 and c < (l-1):\n",
    "        p = np.random.uniform(high=s)\n",
    "        d.append(p)\n",
    "        s -= p\n",
    "        c += 1\n",
    "    d.append(s)\n",
    "    np.random.shuffle(d)\n",
    "    return d\n",
    "\n",
    "def get_marginals(d: dit.Distribution):\n",
    "    rvs = d.get_rv_names()[:-1]  #everything except the output\n",
    "    return d.condition_on(rvs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize probability distribution p(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(dist: np.ndarray):\n",
    "    return st.entropy(dist, base=2)\n",
    "\n",
    "def sample(n_states: int, level: float):\n",
    "    if level < 0 or level >1:\n",
    "        raise ValueError(\"level should be between 0 and 1\")\n",
    "    u = np.ones(n_states)\n",
    "    \n",
    "    #1. Hoe goed Dirichlet distributie begrijpen?\n",
    "    d = np.random.dirichlet(u) # assigns random probabilities to each state; \n",
    "    max_entropy = entropy(u) #=log2(len(n_states))\n",
    "    return d\n",
    "#     if entropy(d)/max_entropy == level:\n",
    "#         return d\n",
    "#     else:\n",
    "#         support, sample_again =  bin_search(d, level)\n",
    "#         # multiply support with a factor so that its a very narrow support\n",
    "#         # 2. Wat gebeurt hier precies? Na binsearching heb je distributie die amper afwijkt van level entropy\n",
    "#         # door onderstaande aanpassing wijkt entropy enigzins af?\n",
    "#         if sample_again:\n",
    "#             support = 1000*support\n",
    "#             return np.random.dirichlet(support)\n",
    "#         else:\n",
    "#             return support \n",
    "\n",
    "def generate_distribution(n_vars: int, n_states: int, entropy_level: float, base=np.e):\n",
    "    var_names = get_vars(n_vars) # generate chosen number of variables, plus Y\n",
    "    state_labels = get_labels(n_vars, n_states) # all possible state combinations for n_vars range  \n",
    "    pmf = sample(n_states**n_vars, level=entropy_level) # prob dist for all possible system states\n",
    "#     if base == np.e:\n",
    "#         pmf = np.log(pmf)\n",
    "    d = dit.Distribution(state_labels, pmf=pmf)\n",
    "    d.set_rv_names(var_names)\n",
    "    old_Y = d.marginal('Y').copy('linear')\n",
    "    old_X, YgivenX = get_marginals(d)\n",
    "    return d, old_X, YgivenX, old_Y\n",
    "\n",
    "def get_dist(all_labels,n_vars):\n",
    "    D = {a: 0 for a in all_labels}\n",
    "    dist = random_dist(len(D))\n",
    "    for i in range(len(D)):\n",
    "        D[all_labels[i]] = np.log(dist[i])\n",
    "    d = Distribution(D,base=np.e)\n",
    "    var_names = get_vars(n_vars) \n",
    "    d.set_rv_names(var_names)\n",
    "\n",
    "    old_Y = d.marginal('Y').copy('linear')\n",
    "    old_X, YgivenX = get_marginals(d)\n",
    "    return d, old_X, YgivenX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential IB (hard clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensenshannon(pygxi, pygxj, pi, pj):\n",
    "    pi_i = pi/(pi + pj)\n",
    "    pi_j = pj/(pi + pj)\n",
    "    p = [(pi_i*pygxi[i]) + (pi_j*pygxj[i]) for i in range(len(pygxi))]\n",
    "    kli = kl(pygxi, p)\n",
    "    klj = kl(pygxj, p)\n",
    "    return (pi_i*kli) + (pi_j*klj) \n",
    "\n",
    "def kl(p, q):\n",
    "    d = 0\n",
    "    for i in range(len(p)):\n",
    "        d += p[i]*np.log2(p[i]/q[i])\n",
    "    return d\n",
    "\n",
    "def update(curX,curC, Xpmf, YgivenX, data):\n",
    "    # update clusters\n",
    "    data[1][curC].remove(curX)\n",
    "    nextC = len(data[2])\n",
    "    data[1][nextC] = [curX]\n",
    "    data[2][curC] -= Xpmf[curX]\n",
    "    data[2].append(Xpmf[curX])\n",
    "\n",
    "    # update p(x|t),p(y|t)\n",
    "    data[3] = xt(Xpmf, data[1], data[2])\n",
    "    pxy = Xpmf[curX]*YgivenX[curX].pmf\n",
    "    data[4][curC] -= (1/data[2][curC])*(pxy) \n",
    "    data[4][nextC] = (1/data[2][nextC])*(pxy)\n",
    "    return data\n",
    "\n",
    "def xt(Xpmf, clusters, cprobs):\n",
    "    # use bayes rule to calculate p(x|t) from p(t|x)\n",
    "    d = {}\n",
    "    for i in range(len(cprobs)):\n",
    "        l = []\n",
    "        for j in range(len(Xpmf)):\n",
    "            if j in clusters[i]:\n",
    "                l.append(Xpmf[j]/cprobs[i])\n",
    "            else:\n",
    "                l.append(0.000000000000001)\n",
    "        d[i] = l\n",
    "    return d\n",
    "\n",
    "def random_partition(numX, M):\n",
    "    clusterprobs = np.zeros(M)\n",
    "    # initialize lookup dictionaries\n",
    "    lookup = {i:i for i in range(numX)}\n",
    "    clusters = {i:[] for i in range(M)}\n",
    "\n",
    "    # assign x randomly to M hard clusters\n",
    "    TgivenX = {i:[] for i in range(numX)}\n",
    "    for i in TgivenX.keys():\n",
    "        u = np.random.randint(0,M)\n",
    "        p = np.zeros(M)\n",
    "        p[u] = 1\n",
    "        lookup[i] = u\n",
    "        clusters[u].append(i)\n",
    "        TgivenX[i] = p\n",
    "        \n",
    "    lens = [len(clusters[i]) for i in clusters.keys()]\n",
    "    print(lens)\n",
    "    if 0 in lens:\n",
    "        return random_partition(numX,M)\n",
    "    \n",
    "    return lookup, clusters, TgivenX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(M, beta, Xpmf, Ypmf, YgivenX, data):\n",
    "    done = True\n",
    "    for k in range(len(Xpmf)):\n",
    "        # find probability and current cluster of xi\n",
    "        curX = k\n",
    "        pr = Xpmf[curX]\n",
    "        curC = data[0][curX]\n",
    "        if len(data[1][curC]) == 1:\n",
    "            continue\n",
    "\n",
    "        # update clusters, cluster probabilities, p(y|t), p(x|t)\n",
    "        data = update(curX, curC, Xpmf, YgivenX, data)\n",
    "        lookup,clusters,cprobs,XgivenT,YgivenT,TY = data \n",
    "        # find cluster with minimum deltaL \n",
    "        minL = []\n",
    "        for i in range(len(cprobs)-1):\n",
    "            pi = cprobs[i]\n",
    "            ptbar = pi+pr\n",
    "            js1 = jensenshannon(YgivenT[i],YgivenT[M],pi,pr)\n",
    "            js2 = jensenshannon(XgivenT[i],XgivenT[M],pi,pr)\n",
    "            minL.append(ptbar*(js1-(js2*(beta**-1))))\n",
    "        minC = np.argmin(minL) \n",
    "        lookup[k] = minC\n",
    "        \n",
    "        # merge x into new cluster if necessary\n",
    "        clusters[minC].append(curX)\n",
    "        cprobs[minC] += pr\n",
    "        YgivenT[minC] = (1/data[2][minC])*sum([Xpmf[x]*YgivenX[x].pmf \n",
    "                                           for x in clusters[minC]])\n",
    "        cprobs.pop(M) \n",
    "        del clusters[M]\n",
    "        \n",
    "        if minC != curC:\n",
    "            done = False\n",
    "\n",
    "    TY = []\n",
    "    for i in range(len(cprobs)):\n",
    "        for j in range(len(YgivenT[i])):\n",
    "            TY.append(cprobs[i]*YgivenT[i][j])\n",
    "    return [lookup, clusters, cprobs, XgivenT, YgivenT, TY], done\n",
    "\n",
    "def init_run(numX,M,old_X, YgivenX,old_Y):\n",
    "    lookup, clusters, TgivenX = random_partition(numX,M)\n",
    "\n",
    "    # calculate cluster probabilities p(t)\n",
    "    clusterprobs = [sum([old_X.pmf[x] for x in clusters[i]]) \n",
    "                    for i in range(M)]\n",
    "    \n",
    "    # calculate p(y|t)\n",
    "    XgivenT = xt(old_X.pmf, clusters, clusterprobs)\n",
    "    YgivenT = {i: [] for i in range(M)}\n",
    "    TY = []\n",
    "    for i in range(M):\n",
    "        s = (1/clusterprobs[i])*sum([old_X.pmf[x]*YgivenX[x].pmf \n",
    "                                     for x in clusters[i]])\n",
    "        YgivenT[i] = s\n",
    "        for j in range(len(s)):\n",
    "            TY.append(s[j]*clusterprobs[i])\n",
    "    return [lookup,clusters,clusterprobs,XgivenT,YgivenT,TY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data \\& distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize data\n",
    "n_states = 2\n",
    "n_input = 4\n",
    "n_output = 1\n",
    "M = 2\n",
    "entropy_level = 1\n",
    "\n",
    "in_labels =  get_labels(n_input, n_states)\n",
    "all_labels = get_labels(n_input+n_output, n_states)\n",
    "2**4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style=\"float: left\"><table border=\"1\"><tr><th>Class:</th><td>Distribution</td></tr><tr><th>Alphabet:</th><td>('0', '1') for all rvs</td></tr><tr><th>Base:</th><td>linear</td></tr><tr><th>Outcome Class:</th><td>str</td></tr><tr><th>Outcome Lenght:</th><td>2</td></tr></table></div><div style=\"float: left\"><table><tr><th>X0</th><th>X1</th><th>p(x)</th></tr><tr><td>0</td><td>0</td><td>0.25</td></tr><tr><td>0</td><td>1</td><td>0.25</td></tr><tr><td>1</td><td>0</td><td>0.25</td></tr><tr><td>1</td><td>1</td><td>0.25</td></tr></table></div></div>"
      ],
      "text/plain": [
       "<dit.npdist.Distribution object at 0x00000235E2110A58>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_X = [1/len(in_labels)]*len(in_labels)\n",
    "py = [1,0.000000001]\n",
    "YgivenX = [[py[0],py[1]],[py[1],py[0]],[py[1],py[0]],[py[0],py[1]],[py[0],py[1]],[py[1],py[0]],[py[1],py[0]],[py[0],py[1]]]\n",
    "XY = [old_X[i]*YgivenX[i][j] for i in range(len(old_X)) for j in range(len(py))]\n",
    "\n",
    "var_names = get_vars(n_input+n_output) # generate chosen number of variables, plus Y\n",
    "d = dit.Distribution(all_labels, XY)\n",
    "d.set_rv_names(var_names)\n",
    "old_Y = d.marginal('Y').copy('linear')\n",
    "old_X, YgivenX = get_marginals(d)\n",
    "old_X.marginal([var_names[0],var_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65536, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((2**(n_input))**(2**(round(n_input/M)))),len(list(combinations(np.arange(n_input),M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_mat(mat,d,labels):\n",
    "    for i in range(len(mat)):\n",
    "        for j in range(len(mat)):\n",
    "            if i < j:\n",
    "                pti = d.marginal([labels[i]]).copy('linear').pmf\n",
    "                ptj = d.marginal([labels[j]]).copy('linear').pmf\n",
    "#                 pt = join(d,[[labels[i]],[labels[j]]])\n",
    "                ty = d.marginal([labels[i],labels[j],labels[-1]])\n",
    "                print(jensenshannon([0.5,0.5], [0.5,0.5], 1/len(mat), 1/len(mat)))\n",
    "                print(jensenshannon([0.5,0.5], [0.5,0.5], 1/len(mat), 1/len(mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style=\"float: left\"><table border=\"1\"><tr><th>Class:</th><td>Distribution</td></tr><tr><th>Alphabet:</th><td>('0', '1') for all rvs</td></tr><tr><th>Base:</th><td>linear</td></tr><tr><th>Outcome Class:</th><td>str</td></tr><tr><th>Outcome Lenght:</th><td>4</td></tr></table></div><div style=\"float: left\"><table><tr><th>X0</th><th>X1</th><th>X2</th><th>Y</th><th>p(x)</th></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0.125</td></tr><tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0.125</td></tr><tr><td>0</td><td>1</td><td>0</td><td>1</td><td>0.125</td></tr><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>0.125</td></tr><tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0.125</td></tr><tr><td>1</td><td>0</td><td>1</td><td>1</td><td>0.125</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1</td><td>0.125</td></tr><tr><td>1</td><td>1</td><td>1</td><td>0</td><td>0.125</td></tr></table></div></div>"
      ],
      "text/plain": [
       "<dit.npdist.Distribution object at 0x000001A302593400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = {i:[i] for i in range(n_input)}\n",
    "mat = np.zeros([n_input,n_input])\n",
    "sel = var_names[:-1]\n",
    "init_mat(mat,d,var_names)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx = ((1/4)*np.log2(4))+((3/4)*(np.log2(4/3)))\n",
    "ygt = 0.75*(((2/3)*np.log2(3/2))+((1/3)*np.log2(3)))\n",
    "entropy(d.marginal(var_names[:-1]).pmf)+entropy(d.marginal(var_names[1:-1]).pmf)-entropy(join(d,[var_names[:-1],var_names[1:-1]]).pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dist = 'dirichlet' # random or dirichlet\n",
    "\n",
    "if type_dist == 'dirichlet':\n",
    "    d, old_X, YgivenX,old_Y = generate_distribution(n_input+n_output,n_states, entropy_level)\n",
    "else:\n",
    "    d, old_X, YgivenX = get_dist(all_labels,n_input+n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial I(X;Y) 1.0\n",
      "0\n",
      "Begin clu {0: [1, 2, 3, 5, 6], 1: [0, 4, 7]}\n",
      "{0: [0, 1, 2, 3, 5, 6], 1: [4, 7]}\n",
      "{0: [0, 1, 2, 3, 5, 6], 1: [4, 7]}\n",
      "1\n",
      "Begin clu {0: [0, 1, 7], 1: [2, 3, 4, 5, 6]}\n",
      "{0: [1, 7], 1: [0, 2, 3, 4, 5, 6]}\n",
      "{0: [1, 7], 1: [0, 2, 3, 4, 5, 6]}\n",
      "2\n",
      "Begin clu {0: [2, 3, 4, 7], 1: [0, 1, 5, 6]}\n",
      "{0: [0, 1, 2, 3, 4, 7], 1: [5, 6]}\n",
      "{0: [0, 1, 2, 3, 4, 7], 1: [5, 6]}\n",
      "3\n",
      "Begin clu {0: [1, 3, 5, 6], 1: [0, 2, 4, 7]}\n",
      "{0: [0, 1, 2, 3, 5, 6], 1: [4, 7]}\n",
      "{0: [0, 1, 2, 3, 5, 6], 1: [4, 7]}\n",
      "4\n",
      "Begin clu {0: [1, 2, 3, 4], 1: [0, 5, 6, 7]}\n",
      "{0: [0, 1, 2, 3, 4, 5], 1: [6, 7]}\n",
      "{0: [0, 1, 2, 3, 4, 5], 1: [6, 7]}\n",
      "5\n",
      "Begin clu {0: [1, 2, 4, 5], 1: [0, 3, 6, 7]}\n",
      "{0: [0, 1, 2, 3, 4, 5], 1: [6, 7]}\n",
      "{0: [0, 1, 2, 3, 4, 5], 1: [6, 7]}\n",
      "6\n",
      "Begin clu {0: [0, 1, 2, 5], 1: [3, 4, 6, 7]}\n",
      "{0: [2, 5], 1: [0, 1, 3, 4, 6, 7]}\n",
      "{0: [2, 5], 1: [0, 1, 3, 4, 6, 7]}\n",
      "7\n",
      "Begin clu {0: [0, 3, 4, 5], 1: [1, 2, 6, 7]}\n",
      "{0: [4, 5], 1: [0, 1, 2, 3, 6, 7]}\n",
      "{0: [4, 5], 1: [0, 1, 2, 3, 6, 7]}\n",
      "8\n",
      "Begin clu {0: [0, 6], 1: [1, 2, 3, 4, 5, 7]}\n",
      "{0: [0, 6], 1: [1, 2, 3, 4, 5, 7]}\n",
      "9\n",
      "Begin clu {0: [0, 7], 1: [1, 2, 3, 4, 5, 6]}\n",
      "{0: [0, 7], 1: [1, 2, 3, 4, 5, 6]}\n"
     ]
    }
   ],
   "source": [
    "beta = 4\n",
    "tot_inputs = n_states**(n_input)\n",
    "M=2\n",
    "runs = []\n",
    "scores = []\n",
    "\n",
    "# run sIB multile times and choose solution which maximizes I(T;Y) - b^-1 * I(X;T)\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    done = False\n",
    "    data = init_run(tot_inputs,M,old_X, YgivenX,old_Y)\n",
    "    print(\"Begin clu\",data[1])\n",
    "    c = 0\n",
    "    while not done and c < 100:\n",
    "        data, done = step(M,beta,old_X.pmf,old_Y.pmf,YgivenX,data)\n",
    "        c += 1\n",
    "        print(data[1])\n",
    "    runs.append(data)\n",
    "    \n",
    "    IYT = entropy(data[2]) + entropy(old_Y.pmf) - entropy(data[-1])\n",
    "    XT = []\n",
    "    for j in range(len(data[2])):\n",
    "        for k in range(len(old_X.pmf)):\n",
    "            XT.append(old_X.pmf[k]*data[3][j][k])\n",
    "    IXT = entropy(old_X.pmf) + entropy(data[2]) - entropy(XT)\n",
    "    scores.append(IYT - ((beta**-1)*IXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21348399520994787, -0.15371466001789835, -0.01854801456046451, -0.018548014560465176, -0.018548014560464732, 0.0758229407736628, 0.012413748972164518, -0.2047780812018818, -0.01854801456046451, -0.0898285096482363]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22bcb053d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def random_color():\n",
    "    rgbl=[255,0,0]\n",
    "    return (random.random(),random.random(),random.random())\n",
    "\n",
    "best = np.argmax(scores)\n",
    "print(scores)\n",
    "Mcolors = [random_color() for _ in range(M)]\n",
    "\n",
    "for i in range(len(old_X.pmf)):\n",
    "    plt.scatter(i,old_X.pmf[i],c=[Mcolors[runs[best][0][i]]])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
